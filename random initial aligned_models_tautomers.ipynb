{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import sys\n",
    "import random\n",
    "\n",
    "path = osp.dirname(osp.abspath(''))\n",
    "sys.path.append(path)\n",
    "sys.path.append(osp.join(path, \"./open_biomed\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_text(path=None):\n",
    "    with open(path, 'r') as f:\n",
    "\n",
    "        text_list = []\n",
    "        for index, line in enumerate(f):\n",
    "            text = line.strip()\n",
    "            text_list.append(text)\n",
    "    return text_list\n",
    "path='./text_after_openai_chemistry_extracted_cleaned.txt'\n",
    "extracted_text=read_text(path=path)\n",
    "path='./text_after_structure_filter.txt'\n",
    "texts=read_text(path=path)\n",
    "\n",
    "# path='./smis_after_structure_filter.txt'\n",
    "# smis=read_text(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_isomers(path=''):\n",
    "    sim_list=[]\n",
    "    with open(path, 'r') as f:\n",
    "        for index, line in enumerate(f):\n",
    "\n",
    "            isomers_list = line.strip().split(\"\\t\")\n",
    "            sim_list.append(isomers_list[0])\n",
    "    return sim_list\n",
    "structure_isomers=structure_isomers(path='./tautomers_ismers.txt')\n",
    "\n",
    "smis=structure_isomers\n",
    "print((len(texts),len(smis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extracted_text),len(texts),len(smis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性核函数，用 PyTorch 实现\n",
    "def linear_kernel(X):\n",
    "    return torch.mm(X, X.T)  # 使用矩阵乘法\n",
    "\n",
    "# 居中核矩阵\n",
    "def center_kernel(K):\n",
    "    n = K.shape[0]\n",
    "    H = torch.eye(n, device=K.device) - torch.ones((n, n), device=K.device) / n  # 中心化矩阵 H\n",
    "    return torch.mm(H, torch.mm(K, H))\n",
    "\n",
    "# CKA 实现，计算两个张量 X 和 Y 的 CKA\n",
    "def CKA(X, Y):\n",
    "    # 计算线性核矩阵\n",
    "    K = linear_kernel(X)\n",
    "    L = linear_kernel(Y)\n",
    "\n",
    "    # 居中核矩阵\n",
    "    Kc = center_kernel(K)\n",
    "    Lc = center_kernel(L)\n",
    "\n",
    "    # 计算 HSIC 值\n",
    "    hsic_XY = torch.trace(torch.mm(Kc, Lc))\n",
    "    hsic_XX = torch.trace(torch.mm(Kc, Kc))\n",
    "    hsic_YY = torch.trace(torch.mm(Lc, Lc))\n",
    "\n",
    "    # 计算 CKA 值\n",
    "    cka_value = hsic_XY / torch.sqrt(hsic_XX * hsic_YY)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return round(cka_value.item(),3)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import cka,gram_linear\n",
    "# structure_feats_np = structure_feats[indes].cpu().detach().numpy()\n",
    "# text_feats_np = text_feats[indes].cpu().detach().numpy()\n",
    "# # Calculate Gram matrices for structure_feats and text_feats\n",
    "def de_biased_cka(structure_feats,text_feats):\n",
    "    structure_feats_np = structure_feats.cpu().detach().numpy()\n",
    "    text_feats_np = text_feats.cpu().detach().numpy()\n",
    "    gram_structure = gram_linear(structure_feats_np)\n",
    "    gram_text = gram_linear(text_feats_np)\n",
    "\n",
    "    # Calculate CKA between the two Gram matrices\n",
    "    cka_value = cka(gram_structure, gram_text, debiased=True)\n",
    "\n",
    "    return round(cka_value,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def retrieve(A, B, K=1):\n",
    "    \"\"\"\n",
    "    检索任务函数，输入两个 tensor A 和 B，返回 A 和 B 匹配的索引值、匹配的分数和正确匹配的条目数。\n",
    "\n",
    "    参数：\n",
    "    - A: torch.Tensor，待匹配的 query tensor，形状 (n, d)。\n",
    "    - B: torch.Tensor，待匹配的 target tensor，形状 (n, d)。\n",
    "    - K: int，检索 top K 匹配。\n",
    "\n",
    "    返回：\n",
    "    - indices: 每个 A 对应的最相似 B 的索引值，形状 (n, K)。\n",
    "    - scores: 每个 A 对应的最相似 B 的分数，形状 (n, K)。\n",
    "    - correct_total: 匹配正确的总条目数。\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算 A 和 B 之间的余弦相似度 (n, n)\n",
    "    similarities = F.cosine_similarity(A.unsqueeze(1), B.unsqueeze(0), dim=-1)\n",
    "    # 获取相似度最高的前 K 个条目的索引和分数\n",
    "    topk_scores, topk_indices = torch.topk(similarities, K, dim=1)\n",
    "    # 计算总的正确匹配数量\n",
    "    # 正确的定义：A[i] 和 B[i] 相匹配，意味着第 i 个 A 应该匹配第 i 个 B\n",
    "    correct_total = 0\n",
    "    n = A.size(0)\n",
    "    for i in range(n):\n",
    "        # 检查 top K 的索引是否包含正确匹配\n",
    "        if i in topk_indices[i]:\n",
    "            correct_total += 1\n",
    "    return topk_indices, topk_scores, correct_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overleap(indexA,indexB ):\n",
    "    C=[]\n",
    "    D=[]\n",
    "    for a, b in zip(indexA, indexB):\n",
    "        overlap = list(set(a) & set(b))\n",
    "        C.append(overlap)\n",
    "        D.append([len(overlap)])\n",
    "\n",
    "    # Print results\n",
    "    print(\"Overlap C:\", C)\n",
    "    print(\"Number of overlaps D:\", D)\n",
    "\n",
    "    sum=0\n",
    "    for i in C:\n",
    "        sum=sum+len(i)\n",
    "    print(sum)\n",
    "    jaccard_similarity=0\n",
    "    for a, b in zip(indexA, indexB):\n",
    "        jaccard_similarity = jaccard_similarity+len(set(a) & set(b)) / len(set(a) | set(b))\n",
    "\n",
    "    print(\"Mean Jaccard Similarity:\", round(jaccard_similarity/len(indexA),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def KM(embedding=None,num_clusters=5):\n",
    "    num_clusters = num_clusters  # You can set this based on your requirement\n",
    "\n",
    "    # Initialize and fit the KMeans model\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(embedding)\n",
    "\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def NN(embedding=None,num=10):\n",
    "    # Initialize the Nearest Neighbors model\n",
    "    num_neighbors = num  # Number of nearest neighbors to find\n",
    "    nn_model = NearestNeighbors(n_neighbors=num_neighbors)\n",
    "\n",
    "    # Fit the model to your data\n",
    "    try:\n",
    "        nn_model.fit(embedding.cpu().numpy())\n",
    "    except:\n",
    "        nn_model.fit(embedding.detach().cpu().numpy())\n",
    "\n",
    "    return nn_model\n",
    "\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# def NN(embedding=None, num=10):\n",
    "#     \"\"\"\n",
    "#     Initialize and fit a Nearest Neighbors model using cosine similarity.\n",
    "\n",
    "#     Parameters:\n",
    "#         embedding (torch.Tensor or np.ndarray): The data to fit the model on.\n",
    "#         num (int): Number of nearest neighbors to find.\n",
    "\n",
    "#     Returns:\n",
    "#         NearestNeighbors: A fitted Nearest Neighbors model.\n",
    "#     \"\"\"\n",
    "#     # Number of nearest neighbors to find\n",
    "#     num_neighbors = num  \n",
    "\n",
    "#     # Initialize the Nearest Neighbors model with cosine similarity\n",
    "#     nn_model = NearestNeighbors(n_neighbors=num_neighbors, metric='cosine')\n",
    "\n",
    "#     # Fit the model to your data\n",
    "#     try:\n",
    "#         nn_model.fit(embedding.cpu().numpy())\n",
    "#     except AttributeError:  # Handle cases where `cpu` is not available\n",
    "#         nn_model.fit(embedding.detach().cpu().numpy())\n",
    "\n",
    "#     return nn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extracted_text),len(smis),len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MolFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "import json\n",
    "from open_biomed.utils.data_utils import DataProcessorFast\n",
    "from open_biomed.utils import fix_path_in_config\n",
    "\n",
    "config = json.load(open(\"./../configs/mtr/molfm.json\", \"r\"))\n",
    "# config['network']['bert_config_path']='../../configs/encoders/multimodal/molfm_bert_config.json'\n",
    "# config['data']['mol']['featurizer']['text']['model_name_or_path']='../../ckpts/text_ckpts/scibert_scivocab_uncased'\n",
    "fix_path_in_config(config, path)\n",
    "print(\"Config: \", config)\n",
    "processor = DataProcessorFast(entity_type=\"molecule\", config=config[\"data\"][\"mol\"])\n",
    "processor.featurizer.set_mol2text_dict(dict(zip(smis, texts)))\n",
    "mols = processor(smis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from open_biomed.models.multimodal import MolFM\n",
    "model = MolFM(config[\"network\"])\n",
    "# state_dict = torch.load(\"./../ckpts/fusion_ckpts/MolFM.pth\", map_location=\"cpu\")[\"model\"]\n",
    "# model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    structure_feats = model.encode_mol(mols[\"structure\"].to(device), proj=True)\n",
    "    text_feats = model.encode_text(mols[\"text\"].to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_feats.shape,text_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKA(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_biased_cka(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices_k1, scores_k1, correct_total_k1 = retrieve(A.to(device), B.to(device), K=1)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices_k1)\n",
    "# print(\"Top K 分数：\", scores_k1)\n",
    "print(\"正确匹配的条目数：\", correct_total_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices, scores, correct_total = retrieve(A.to(device), B.to(device), K=10)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices)\n",
    "# print(\"Top K 分数：\", scores)\n",
    "print(\"正确匹配的条目数：\", correct_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_NN=NN(embedding=B)\n",
    "texts_NN_distance,texts_NN_indes=texts_NN.kneighbors(B.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), texts_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis_NN=NN(embedding=A)\n",
    "smis_NN_distance,smis_NN_indes=smis_NN.kneighbors(A.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), smis_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "### texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "texts_KM=KM(B.cpu().numpy())\n",
    "cls_index=texts_KM.predict(B.cpu().numpy())\n",
    "\n",
    "C=B[indices_k1.cpu()].reshape(B.shape).cpu().numpy()\n",
    "match_index=texts_KM.predict(C)\n",
    "x=cls_index==match_index\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2896/3515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### smis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A =structure_feats\n",
    "# B = text_feats\n",
    "\n",
    "smis_KM=KM(A.cpu().numpy())\n",
    "\n",
    "smis_index=smis_KM.predict(A.cpu().numpy())\n",
    "\n",
    "C=A[indices_k1.cpu()].reshape(A.shape).cpu().numpy()\n",
    "match_index=smis_KM.predict(C)\n",
    "\n",
    "x=smis_index==match_index\n",
    "\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "import json\n",
    "from open_biomed.utils.data_utils import DataProcessorFast\n",
    "from open_biomed.utils import fix_path_in_config\n",
    "\n",
    "config = json.load(open(\"./../configs/mtr/molfm.json\", \"r\"))\n",
    "# config['network']['bert_config_path']='../../configs/encoders/multimodal/molfm_bert_config.json'\n",
    "# config['data']['mol']['featurizer']['text']['model_name_or_path']='../../ckpts/text_ckpts/scibert_scivocab_uncased'\n",
    "\n",
    "fix_path_in_config(config, path)\n",
    "print(\"Config: \", config)\n",
    "processor = DataProcessorFast(entity_type=\"molecule\", config=config[\"data\"][\"mol\"])\n",
    "processor.featurizer.set_mol2text_dict(dict(zip(smis, extracted_text)))\n",
    "mols = processor(smis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from open_biomed.models.multimodal import MolFM\n",
    "model = MolFM(config[\"network\"])\n",
    "# state_dict = torch.load(\"./../ckpts/fusion_ckpts/MolFM.pth\", map_location=\"cpu\")[\"model\"]\n",
    "# model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    structure_feats = model.encode_mol(mols[\"structure\"].to(device), proj=True)\n",
    "    text_feats = model.encode_text(mols[\"text\"].to(device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_biased_cka(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKA(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices_k1, scores_k1, correct_total_k1 = retrieve(A.to(device), B.to(device), K=1)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices_k1)\n",
    "# print(\"Top K 分数：\", scores_k1)\n",
    "print(\"正确匹配的条目数：\", correct_total_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices, scores, correct_total = retrieve(A.to(device), B.to(device), K=10)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices)\n",
    "# print(\"Top K 分数：\", scores)\n",
    "print(\"正确匹配的条目数：\", correct_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_NN=NN(embedding=B)\n",
    "texts_NN_distance,texts_NN_indes=texts_NN.kneighbors(B.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), texts_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis_NN=NN(embedding=A)\n",
    "smis_NN_distance,smis_NN_indes=smis_NN.kneighbors(A.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), smis_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "### texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "texts_KM=KM(B.cpu().numpy())\n",
    "cls_index=texts_KM.predict(B.cpu().numpy())\n",
    "\n",
    "C=B[indices_k1.cpu()].reshape(B.shape).cpu().numpy()\n",
    "match_index=texts_KM.predict(C)\n",
    "x=cls_index==match_index\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### smis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A =structure_feats\n",
    "# B = text_feats\n",
    "\n",
    "smis_KM=KM(A.cpu().numpy())\n",
    "\n",
    "smis_index=smis_KM.predict(A.cpu().numpy())\n",
    "\n",
    "C=A[indices_k1.cpu()].reshape(A.shape).cpu().numpy()\n",
    "match_index=smis_KM.predict(C)\n",
    "\n",
    "x=smis_index==match_index\n",
    "\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MoMu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "import json\n",
    "from open_biomed.utils.data_utils import DataProcessorFast\n",
    "from open_biomed.utils import fix_path_in_config\n",
    "\n",
    "config = json.load(open(\"./../configs/mtr/momu.json\", \"r\"))\n",
    "# config['data']['mol']['featurizer']['text']['model_name_or_path']='../../ckpts/text_ckpts/scibert_scivocab_uncased'\n",
    "\n",
    "fix_path_in_config(config, path)\n",
    "print(\"Config: \", config)\n",
    "# print(config[\"data\"][\"mol\"])\n",
    "processor = DataProcessorFast(entity_type=\"molecule\", config=config[\"data\"][\"mol\"])\n",
    "processor.featurizer.set_mol2text_dict(dict(zip(smis, texts)))\n",
    "mols = processor(smis)\n",
    "\n",
    "\n",
    "# config = json.load(open(\"./../configs/mtr/molfm.json\", \"r\"))\n",
    "# # config['network']['bert_config_path']='../../configs/encoders/multimodal/molfm_bert_config.json'\n",
    "# # config['data']['mol']['featurizer']['text']['model_name_or_path']='../../ckpts/text_ckpts/scibert_scivocab_uncased'\n",
    "# fix_path_in_config(config, path)\n",
    "# print(\"Config: \", config)\n",
    "# processor = DataProcessorFast(entity_type=\"molecule\", config=config[\"data\"][\"mol\"])\n",
    "# processor.featurizer.set_mol2text_dict(dict(zip(smis, texts)))\n",
    "# mols = processor(smis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from open_biomed.models.multimodal import MoMu\n",
    "model = MoMu(config[\"network\"])\n",
    "# state_dict = torch.load(\"../ckpts/fusion_ckpts/MoMu-S.ckpt\", map_location=\"cuda\")\n",
    "# print(state_dict)\n",
    "# state_dict = torch.load(\"../ckpts/fusion_ckpts/MoMu-K.ckpt\", map_location=\"cuda\")[\"model\"]\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     structure_feats = model.encode_mol(mols[\"structure\"], proj=True)\n",
    "#     text_feats = model.encode_text(mols[\"text\"])\n",
    "\n",
    "# for i in range(len(smis)):\n",
    "#     similarity = torch.cosine_similarity(structure_feats[i], text_feats)\n",
    "#     best = torch.argmax(similarity).item()\n",
    "#     print(\"Similarity for \", smis[i], \"is\", similarity.numpy(), \", Retrieved text is \\\"\", texts[best], \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     structure_feats = model.encode_mol(mols[\"structure\"], proj=True)\n",
    "#     text_feats = model.encode_text(mols[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    structure_feats = model.encode_mol(mols[\"structure\"].to(device), proj=True)\n",
    "    text_feats = model.encode_text(mols[\"text\"].to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_feats.shape,text_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKA(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_biased_cka(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices_k1, scores_k1, correct_total_k1 = retrieve(A.to(device), B.to(device), K=1)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices_k1)\n",
    "# print(\"Top K 分数：\", scores_k1)\n",
    "print(\"正确匹配的条目数：\", correct_total_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices, scores, correct_total = retrieve(A.to(device), B.to(device), K=10)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices)\n",
    "# print(\"Top K 分数：\", scores)\n",
    "print(\"正确匹配的条目数：\", correct_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_NN=NN(embedding=B)\n",
    "texts_NN_distance,texts_NN_indes=texts_NN.kneighbors(B.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), texts_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis_NN=NN(embedding=A)\n",
    "smis_NN_distance,smis_NN_indes=smis_NN.kneighbors(A.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), smis_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "### texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "texts_KM=KM(B.cpu().numpy())\n",
    "cls_index=texts_KM.predict(B.cpu().numpy())\n",
    "\n",
    "C=B[indices_k1.cpu()].reshape(B.shape).cpu().numpy()\n",
    "match_index=texts_KM.predict(C)\n",
    "x=cls_index==match_index\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2718/3515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### smis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A =structure_feats\n",
    "# B = text_feats\n",
    "\n",
    "smis_KM=KM(A.cpu().numpy())\n",
    "\n",
    "smis_index=smis_KM.predict(A.cpu().numpy())\n",
    "\n",
    "C=A[indices_k1.cpu()].reshape(A.shape).cpu().numpy()\n",
    "match_index=smis_KM.predict(C)\n",
    "\n",
    "x=smis_index==match_index\n",
    "\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "import json\n",
    "from open_biomed.utils.data_utils import DataProcessorFast\n",
    "from open_biomed.utils import fix_path_in_config\n",
    "\n",
    "config = json.load(open(\"./../configs/mtr/momu.json\", \"r\"))\n",
    "# config['data']['mol']['featurizer']['text']['model_name_or_path']='../../ckpts/text_ckpts/scibert_scivocab_uncased'\n",
    "\n",
    "fix_path_in_config(config, path)\n",
    "print(\"Config: \", config)\n",
    "processor = DataProcessorFast(entity_type=\"molecule\", config=config[\"data\"][\"mol\"])\n",
    "processor.featurizer.set_mol2text_dict(dict(zip(smis, extracted_text)))\n",
    "mols = processor(smis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    structure_feats = model.encode_mol(mols[\"structure\"].to(device), proj=True)\n",
    "    text_feats = model.encode_text(mols[\"text\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_feats.shape,text_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKA(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_biased_cka(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices_k1, scores_k1, correct_total_k1 = retrieve(A.to(device), B.to(device), K=1)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices_k1)\n",
    "# print(\"Top K 分数：\", scores_k1)\n",
    "print(\"正确匹配的条目数：\", correct_total_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices, scores, correct_total = retrieve(A.to(device), B.to(device), K=10)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices)\n",
    "# print(\"Top K 分数：\", scores)\n",
    "print(\"正确匹配的条目数：\", correct_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_NN=NN(embedding=B)\n",
    "texts_NN_distance,texts_NN_indes=texts_NN.kneighbors(B.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), texts_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis_NN=NN(embedding=A)\n",
    "smis_NN_distance,smis_NN_indes=smis_NN.kneighbors(A.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), smis_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "### texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "texts_KM=KM(B.cpu().numpy())\n",
    "cls_index=texts_KM.predict(B.cpu().numpy())\n",
    "\n",
    "C=B[indices_k1.cpu()].reshape(B.shape).cpu().numpy()\n",
    "match_index=texts_KM.predict(C)\n",
    "x=cls_index==match_index\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2732/3515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### smis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A =structure_feats\n",
    "# B = text_feats\n",
    "\n",
    "smis_KM=KM(A.cpu().numpy())\n",
    "\n",
    "smis_index=smis_KM.predict(A.cpu().numpy())\n",
    "\n",
    "C=A[indices_k1.cpu()].reshape(A.shape).cpu().numpy()\n",
    "match_index=smis_KM.predict(C)\n",
    "\n",
    "x=smis_index==match_index\n",
    "\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clamp\n",
    "\n",
    "model = clamp.CLAMP(device='cpu')\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(extracted_text),len(smis),len(texts)\n",
    "\n",
    "text_feats=model.encode_text(texts).to(device)\n",
    "\n",
    "structure_feats=model.encode_smiles(smis).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(structure_feats),len(text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_feats.shape,text_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKA(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_biased_cka(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices_k1, scores_k1, correct_total_k1 = retrieve(A.to('cpu'), B.to('cpu'), K=1)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices_k1)\n",
    "# print(\"Top K 分数：\", scores_k1)\n",
    "print(\"正确匹配的条目数：\", correct_total_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices, scores, correct_total = retrieve(A.to('cpu'), B.to('cpu'), K=10)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices)\n",
    "# print(\"Top K 分数：\", scores)\n",
    "print(\"正确匹配的条目数：\", correct_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_NN=NN(embedding=B)\n",
    "texts_NN_distance,texts_NN_indes=texts_NN.kneighbors(B.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), texts_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis_NN=NN(embedding=A)\n",
    "smis_NN_distance,smis_NN_indes=smis_NN.kneighbors(A.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), smis_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "### texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "texts_KM=KM(B.cpu().numpy())\n",
    "cls_index=texts_KM.predict(B.cpu().numpy())\n",
    "\n",
    "C=B[indices_k1.cpu()].reshape(B.shape).cpu().numpy()\n",
    "match_index=texts_KM.predict(C)\n",
    "x=cls_index==match_index\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2718/3515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### smis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A =structure_feats\n",
    "# B = text_feats\n",
    "\n",
    "smis_KM=KM(A.cpu().numpy())\n",
    "\n",
    "smis_index=smis_KM.predict(A.cpu().numpy())\n",
    "\n",
    "C=A[indices_k1.cpu()].reshape(A.shape).cpu().numpy()\n",
    "match_index=smis_KM.predict(C)\n",
    "\n",
    "x=smis_index==match_index\n",
    "\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feats=model.encode_text(extracted_text).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_feats.shape,text_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKA(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_biased_cka(structure_feats,text_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices_k1, scores_k1, correct_total_k1 = retrieve(A.to('cpu'), B.to('cpu'), K=1)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices_k1)\n",
    "# print(\"Top K 分数：\", scores_k1)\n",
    "print(\"正确匹配的条目数：\", correct_total_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =structure_feats\n",
    "B = text_feats\n",
    "indices, scores, correct_total = retrieve(A.to('cpu'), B.to('cpu'), K=10)\n",
    "# 打印结果\n",
    "# print(\"Top K 索引：\", indices)\n",
    "# print(\"Top K 分数：\", scores)\n",
    "print(\"正确匹配的条目数：\", correct_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_NN=NN(embedding=B)\n",
    "texts_NN_distance,texts_NN_indes=texts_NN.kneighbors(B.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), texts_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis_NN=NN(embedding=A)\n",
    "smis_NN_distance,smis_NN_indes=smis_NN.kneighbors(A.cpu().detach())\n",
    "overleap(indices.cpu().numpy(), smis_NN_indes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "### texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "texts_KM=KM(B.cpu().numpy())\n",
    "cls_index=texts_KM.predict(B.cpu().numpy())\n",
    "\n",
    "C=B[indices_k1.cpu()].reshape(B.shape).cpu().numpy()\n",
    "match_index=texts_KM.predict(C)\n",
    "x=cls_index==match_index\n",
    "np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2718/3515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### smis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A =structure_feats\n",
    "# B = text_feats\n",
    "\n",
    "smis_KM=KM(A.cpu().numpy())\n",
    "\n",
    "smis_index=smis_KM.predict(A.cpu().numpy())\n",
    "\n",
    "C=A[indices_k1.cpu()].reshape(A.shape).cpu().numpy()\n",
    "match_index=smis_KM.predict(C)\n",
    "\n",
    "x=smis_index==match_index\n",
    "\n",
    "np.sum(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenBioMed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
